{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of EIGHTH.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahalrupi/EIP-4.0/blob/master/Week2/Copy_of_EIGHTH.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SJyVpgSxHt4",
        "colab_type": "code",
        "outputId": "fbf5c2a9-be82-4177-d241-6c3512309651",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add, BatchNormalization\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlEUplvoxKAT",
        "colab_type": "code",
        "outputId": "82e9910f-9468-4852-91e5-e8150778354f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6Y9Va-xxMXG",
        "colab_type": "code",
        "outputId": "c803d767-3bfc-42e2-fdc4-3e93e44a699a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[991])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7efd36f99a20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/w/Q9SPFaGN6OAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxDZxPhhxOgO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HzMqbTnxQQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LdYiW6ixR9e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train[:10]\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFR0F9j0xVp2",
        "colab_type": "code",
        "outputId": "d0201149-75de-4862-b98b-daa00bc11fba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "Y_train[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDpXf4YQxXRm",
        "colab_type": "code",
        "outputId": "b48655d0-3338-42bf-b556-1f468ebaaf57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        " \n",
        "model.add(Convolution2D(16, 3, 3, activation='relu',bias=False, input_shape=(28,28,1))) #26\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.05))\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3,bias=False, activation='relu')) #24\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.05))\n",
        "\n",
        "model.add(Convolution2D(8, 1, 1,bias=False, activation='relu')) #22\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))#11\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3,bias=False, activation='relu'))#9\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.05))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3,bias=False, activation='relu'))#7\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.05))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3,bias=False, activation='relu'))#5\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.05))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3,bias=False, activation='relu'))#3\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.05))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(10, 4, 4,bias=False,))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.05))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", input_shape=(28, 28, 1..., use_bias=False)`\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", use_bias=False)`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (1, 1), activation=\"relu\", use_bias=False)`\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", use_bias=False)`\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", use_bias=False)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", use_bias=False)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", use_bias=False)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (4, 4), use_bias=False)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 16)        144       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 26, 26, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 16)        2304      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 24, 24, 8)         128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 10, 10, 16)        1152      \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 10, 10, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 10, 10, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 16)          2304      \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 8, 8, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 6, 6, 16)          2304      \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 6, 6, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 6, 6, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 4, 4, 16)          2304      \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 4, 4, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 4, 4, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 1, 1, 10)          2560      \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 1, 1, 10)          40        \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 1, 1, 10)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 13,624\n",
            "Trainable params: 13,412\n",
            "Non-trainable params: 212\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2IicGJ4x3Be",
        "colab_type": "code",
        "outputId": "b4353363-5cce-47c7-b301-6768ecd4c8e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=1, validation_data=(X_test, Y_test), callbacks=[LearningRateScheduler(scheduler, verbose=1)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "60000/60000 [==============================] - 11s 180us/step - loss: 0.4229 - acc: 0.9002 - val_loss: 0.0910 - val_acc: 0.9847\n",
            "Epoch 2/20\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "60000/60000 [==============================] - 6s 98us/step - loss: 0.1753 - acc: 0.9545 - val_loss: 0.0618 - val_acc: 0.9879\n",
            "Epoch 3/20\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "60000/60000 [==============================] - 6s 97us/step - loss: 0.1375 - acc: 0.9641 - val_loss: 0.0400 - val_acc: 0.9903\n",
            "Epoch 4/20\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "60000/60000 [==============================] - 6s 97us/step - loss: 0.1149 - acc: 0.9717 - val_loss: 0.0373 - val_acc: 0.9912\n",
            "Epoch 5/20\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.1031 - acc: 0.9731 - val_loss: 0.0365 - val_acc: 0.9909\n",
            "Epoch 6/20\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0920 - acc: 0.9752 - val_loss: 0.0322 - val_acc: 0.9919\n",
            "Epoch 7/20\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0839 - acc: 0.9780 - val_loss: 0.0282 - val_acc: 0.9918\n",
            "Epoch 8/20\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "60000/60000 [==============================] - 6s 97us/step - loss: 0.0751 - acc: 0.9799 - val_loss: 0.0293 - val_acc: 0.9922\n",
            "Epoch 9/20\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "60000/60000 [==============================] - 6s 94us/step - loss: 0.0714 - acc: 0.9801 - val_loss: 0.0295 - val_acc: 0.9917\n",
            "Epoch 10/20\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0641 - acc: 0.9815 - val_loss: 0.0271 - val_acc: 0.9924\n",
            "Epoch 11/20\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "60000/60000 [==============================] - 6s 94us/step - loss: 0.0616 - acc: 0.9820 - val_loss: 0.0229 - val_acc: 0.9935\n",
            "Epoch 12/20\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0596 - acc: 0.9827 - val_loss: 0.0232 - val_acc: 0.9934\n",
            "Epoch 13/20\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0558 - acc: 0.9828 - val_loss: 0.0211 - val_acc: 0.9939\n",
            "Epoch 14/20\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "60000/60000 [==============================] - 6s 94us/step - loss: 0.0536 - acc: 0.9838 - val_loss: 0.0226 - val_acc: 0.9940\n",
            "Epoch 15/20\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0512 - acc: 0.9833 - val_loss: 0.0215 - val_acc: 0.9939\n",
            "Epoch 16/20\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "60000/60000 [==============================] - 6s 94us/step - loss: 0.0487 - acc: 0.9839 - val_loss: 0.0209 - val_acc: 0.9941\n",
            "Epoch 17/20\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "60000/60000 [==============================] - 6s 99us/step - loss: 0.0498 - acc: 0.9827 - val_loss: 0.0207 - val_acc: 0.9940\n",
            "Epoch 18/20\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "60000/60000 [==============================] - 6s 99us/step - loss: 0.0464 - acc: 0.9839 - val_loss: 0.0203 - val_acc: 0.9937\n",
            "Epoch 19/20\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "60000/60000 [==============================] - 6s 98us/step - loss: 0.0451 - acc: 0.9845 - val_loss: 0.0212 - val_acc: 0.9942\n",
            "Epoch 20/20\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0441 - acc: 0.9849 - val_loss: 0.0192 - val_acc: 0.9952\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efd36aac240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLxlW9ufyQiO",
        "colab_type": "code",
        "outputId": "fd57bf71-55fb-41b2-92b4-f6361d0529c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.019211676144856027, 0.9952]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNRrouUMCfX-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}